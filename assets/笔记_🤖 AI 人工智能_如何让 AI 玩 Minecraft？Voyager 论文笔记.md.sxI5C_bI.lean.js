import{_ as u,c,I as a,j as r,w as n,a as e,au as o,D as l,o as g}from"./chunks/framework.RMxno62p.js";const h="/assets/Pasted%20image%2020240710155310.MlsFBsEp.png",Y=JSON.parse('{"title":"如何让 AI 玩 Minecraft？","description":"","frontmatter":{"tags":["AI","游戏/Minecraft","AI/大语言模型/LLM","AI/强化学习/Reinforcement-learning/RL","AI/多模态/Code-as-policies","笔记/论文"]},"headers":[],"relativePath":"笔记/🤖 AI 人工智能/如何让 AI 玩 Minecraft？Voyager 论文笔记.md","filePath":"笔记/🤖 AI 人工智能/如何让 AI 玩 Minecraft？Voyager 论文笔记.md"}'),b={name:"笔记/🤖 AI 人工智能/如何让 AI 玩 Minecraft？Voyager 论文笔记.md"},_=r("h1",{id:"如何让-ai-玩-minecraft",tabindex:"-1"},[e("如何让 AI 玩 Minecraft？ "),r("a",{class:"header-anchor",href:"#如何让-ai-玩-minecraft","aria-label":'Permalink to "如何让 AI 玩 Minecraft？"'},"​")],-1),v=o("",3),m={id:"voyager-an-open-ended-embodied-agent-with-large-language-models",tabindex:"-1"},p=r("a",{class:"header-anchor",href:"#voyager-an-open-ended-embodied-agent-with-large-language-models","aria-label":'Permalink to "[Voyager | An Open-Ended Embodied Agent with Large Language Models](https://voyager.minedojo.org/)"'},"​",-1),P=r("span",{class:"text-sm px-1 py-0.5 border border-solid border-orange-500/30 text-orange-400 bg-orange-500/20 rounded-lg"},"Watch",-1),A=r("span",{class:"text-sm px-1 py-0.5 border border-solid border-orange-500/30 text-orange-400 bg-orange-500/20 rounded-lg"},"Read",-1),L=r("span",{class:"text-sm px-1 py-0.5 border border-solid border-orange-500/30 text-orange-400 bg-orange-500/20 rounded-lg"},"Read",-1),y=r("span",{class:"text-sm px-1 py-0.5 border border-solid border-orange-500/30 text-orange-400 bg-orange-500/20 rounded-lg"},"Read",-1),M=o("",3),w=r("li",null,"😱 这里面会有一些机器学习或者强化学习的坑，比如事实上包括 Voyager 和其他的类似的 Planning Agent 都是站在「人类行为」的假设上进行的",-1),x=r("li",null,"❓ 有一个比较有趣的思考是：和 MineDojo 这样的 Minecraft API 调用环境不同的是，其实如果我们期望在现实世界中给机器人（robotics）添加 LLM 的 code generation 能力，我们的机器人是不会获得任何的可以用于 CoT 的错误的，因为现实世界中不会返回错误，它更不可能有一个像是 API 调用一样的文本形式的错误可以让我们以文本的形式输入给 LLM",-1),q=r("li",null,"❓ Voyager 的实现中提到的 Nearby Entities 是一个非常明确的，Agent 本身自己会知道的精确的地址的游戏对象，比如如果旁边 32 块内有一个僵尸，那么 Agent 会通过 API 的形式直接知道有僵尸，以及僵尸在什么地方，这个实现和 OpenAI 的 DOTA Bot 类似，DOTA Bot 就是建立在对游戏内对局状态的非常全面的了解之上的。但是对于人类玩家而言我们是不会知道的，通常我们如果屏幕中看不到僵尸的话要么是能听到，要么是小地图上能看到。",-1),T={id:"plan4mc",tabindex:"-1"},z=r("a",{class:"header-anchor",href:"#plan4mc","aria-label":'Permalink to "[Plan4MC](https://sites.google.com/view/plan4mc)"'},"​",-1),k=r("span",{class:"text-sm px-1 py-0.5 border border-solid border-orange-500/30 text-orange-400 bg-orange-500/20 rounded-lg"},"Read",-1),N={id:"diffusion-forcing-next-token-prediction-meets-full-sequence-diffusion",tabindex:"-1"},C=r("a",{class:"header-anchor",href:"#diffusion-forcing-next-token-prediction-meets-full-sequence-diffusion","aria-label":'Permalink to "[Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion](https://boyuan.space/diffusion-forcing/)"'},"​",-1),I=o("",2),S=r("h2",{id:"社区和资源",tabindex:"-1"},[e("社区和资源 "),r("a",{class:"header-anchor",href:"#社区和资源","aria-label":'Permalink to "社区和资源"'},"​")],-1),D=r("h2",{id:"工具",tabindex:"-1"},[e("工具 "),r("a",{class:"header-anchor",href:"#工具","aria-label":'Permalink to "工具"'},"​")],-1),V=r("li",null,"Minecraft 接口",-1),K=r("h2",{id:"强化学习",tabindex:"-1"},[e("强化学习 "),r("a",{class:"header-anchor",href:"#强化学习","aria-label":'Permalink to "强化学习"'},"​")],-1),H=r("s",null,"openai/gym: A toolkit for developing and comparing reinforcement learning algorithms.",-1),X=r("h2",{id:"数据集",tabindex:"-1"},[e("数据集 "),r("a",{class:"header-anchor",href:"#数据集","aria-label":'Permalink to "数据集"'},"​")],-1);function E(j,B,G,O,R,W){const i=l("NolebasePageProperties"),t=l("VPNolebaseInlineLinkPreview"),s=l("NolebaseUnlazyImg"),f=l("NolebaseGitContributors"),d=l("NolebaseGitChangelog");return g(),c("div",null,[_,a(i),v,r("h3",m,[a(t,{href:"https://voyager.minedojo.org/",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("Voyager | An Open-Ended Embodied Agent with Large Language Models")]),_:1}),e(),p]),r("ul",null,[r("li",null,[e("[x] "),P,e(),a(t,{href:"https://github.com/hu-po",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("@hu-po")]),_:1}),e(" 大佬制作的解析视频："),a(t,{href:"https://www.youtube.com/watch?v=hhawa3tFN2s&t=2270s",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("Voyager: LLMs play Minecraft (youtube.com)")]),_:1})]),r("li",null,[e("[x] "),A,e(),a(t,{href:"https://github.com/MineDojo/Voyager",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("MineDojo/Voyager: An Open-Ended Embodied Agent with Large Language Models")]),_:1})]),r("li",null,[e("[x] "),L,e(),a(t,{href:"https://www.reddit.com/r/MachineLearning/comments/13sc0pp/voyager_an_llmpowered_learning_agent_in_minecraft/",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("Voyager: An LLM-powered learning agent in Minecraft : r/MachineLearning (reddit.com)")]),_:1})]),r("li",null,[e("[x] "),y,e(),a(t,{href:"https://arxiv.org/abs/2309.09971",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("MindAgent: Emergent Gaming Interaction")]),_:1}),e("，"),a(t,{href:"https://ar5iv.labs.arxiv.org/html/2309.09971",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("HTML 版本")]),_:1})])]),M,r("ul",null,[w,r("li",null,[e("💡 分享到了另外的一个 "),a(t,{href:"https://arxiv.org/abs/2304.03442",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("2304.03442 Generative Agents: Interactive Simulacra of Human Behavior")]),_:1}),e(" 论文，这篇论文把大佬说服了认为我们可能活在模拟程序中，"),a(t,{href:"https://ar5iv.labs.arxiv.org/html/2304.03442",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("HTML 版本")]),_:1})]),x,q,r("li",null,[e("拓展： "),r("ul",null,[r("li",null,[e("💡 论文引用了两篇论文提到了我们可以用大语言模型生成机器人可以直接执行的策略： "),r("ul",null,[r("li",null,[a(t,{href:"https://arxiv.org/abs/2209.07753",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("2209.07753 Code as Policies: Language Model Programs for Embodied Control (arxiv.org)")]),_:1}),e("，"),a(t,{href:"https://ar5iv.labs.arxiv.org/html/2209.07753",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("HTML 版本")]),_:1})]),r("li",null,[a(t,{href:"https://arxiv.org/abs/2209.11302",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("2209.11302 ProgPrompt: Generating Situated Robot Task Plans using Large Language Models")]),_:1}),e("，"),a(t,{href:"https://ar5iv.labs.arxiv.org/html/2209.11302",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("HTML 版本")]),_:1})])])]),r("li",null,[a(t,{href:"https://www.youtube.com/watch?v=1Gl93N2nhcE",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("Robots using LLMs - YouTube")]),_:1})])])])]),r("h3",T,[a(t,{href:"https://sites.google.com/view/plan4mc",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("Plan4MC")]),_:1}),e(),z]),r("ul",null,[r("li",null,[e("[ ] "),k,e(" 解析视频："),a(t,{href:"https://www.bilibili.com/video/BV1Cu411K7NR",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("LLM论文分享--我的世界的智能体代理Plan4MC，大语言模型给AI智能体做技能规划 - bilibili")]),_:1})]),r("li",null,[e("[ ] "),a(t,{href:"https://arxiv.org/html/2303.16563v2",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("Skill Reinforcement Learning and Planning for Open-World Long-Horizon Tasks")]),_:1})]),r("li",null,[e("[ ] "),a(t,{href:"https://github.com/PKU-RL/Plan4MC",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("PKU-RL/Plan4MC: Reinforcement learning and planning for Minecraft.")]),_:1})])]),r("h3",N,[a(t,{href:"https://boyuan.space/diffusion-forcing/",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion")]),_:1}),e(),C]),I,r("p",null,[a(s,{src:h,alt:"",thumbhash:"MAgGFIL2eZWPmVelZotoeUCBCQ==",placeholderSrc:"data:image/png;base64,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",width:"3664",height:"2058",autoSizes:"true"})]),r("ul",null,[r("li",null,[r("p",null,[a(t,{href:"https://www.youtube.com/watch?v=cXfnNoMgCio",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("How Large Language Models play video games - YouTube")]),_:1})])]),r("li",null,[r("p",null,[a(t,{href:"https://arxiv.org/abs/2109.06780",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("2109.06780 Benchmarking the Spectrum of Agent Capabilities")]),_:1}),e("，"),a(t,{href:"https://ar5iv.labs.arxiv.org/html/2109.06780",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("HTML 版本")]),_:1})])]),r("li",null,[r("p",null,[a(t,{href:"https://arxiv.org/abs/2305.15486",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("2305.15486 SPRING: Studying the Paper and Reasoning to Play Games")]),_:1}),e("，"),a(t,{href:"https://ar5iv.labs.arxiv.org/html/2305.15486",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("HTML 版本")]),_:1})])]),r("li",null,[r("p",null,[a(t,{href:"https://arxiv.org/abs/2302.04449",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("2302.04449 Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals")]),_:1}),e("，"),a(t,{href:"https://ar5iv.labs.arxiv.org/html/2302.04449",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("HTML 版本")]),_:1})])])]),S,r("ul",null,[r("li",null,[a(t,{href:"https://minerl.readthedocs.io/en/latest/",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("MineRL: Towards AI in Minecraft — MineRL 0.4.0 documentation")]),_:1})])]),D,r("ul",null,[V,r("li",null,[a(t,{href:"https://minerl.readthedocs.io/en/latest/notes/interfaces.html#minedojo",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("Other Minecraft Interfaces — MineRL 0.4.0 documentation")]),_:1})]),r("li",null,[a(t,{href:"https://minedojo.org/",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("MineDojo | Building Open-Ended Embodied Agents with Internet-Scale Knowledge")]),_:1})])]),K,r("ul",null,[r("li",null,[a(t,{href:"https://github.com/openai/gym?tab=readme-ov-file",target:"_blank",rel:"noreferrer"},{default:n(()=>[H]),_:1}),e(" 已经挪到 "),a(t,{href:"https://github.com/Farama-Foundation/Gymnasium",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("Farama-Foundation/Gymnasium: An API standard for single-agent reinforcement learning environments, with popular reference environments and related utilities (formerly Gym)")]),_:1}),e(" 去维护了")])]),X,r("ul",null,[r("li",null,[a(t,{href:"https://github.com/MineDojo/MineCLIP",target:"_blank",rel:"noreferrer"},{default:n(()=>[e("MineDojo/MineCLIP: Foundation Model for MineDojo")]),_:1})])]),a(f),a(d)])}const Q=u(b,[["render",E]]);export{Y as __pageData,Q as default};
